{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Senne\\AI_Frameworks\\Project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import pillow_heif\n",
    "import cv2\n",
    "\n",
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "from keras_facenet import FaceNet\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extensions found in the folder:\n"
     ]
    }
   ],
   "source": [
    "test_data = glob('testset/testset/*.jpg')\n",
    "source_folder = \"Testset/Testset\"\n",
    "output_folder = \"Testset/Testset\"\n",
    "\n",
    "def list_extensions(folder_path):\n",
    "    extensions = set()\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            _, extension = os.path.splitext(filename)\n",
    "            extensions.add(extension.lower())\n",
    "    return extensions\n",
    "\n",
    "def convert_to_jpg(file_path, source_folder):\n",
    "    try:\n",
    "        _, extension = os.path.splitext(file_path)\n",
    "        extension = extension.lower()\n",
    "\n",
    "        if extension == \".heic\":\n",
    "            heif_file = pillow_heif.open_heif(file_path)\n",
    "            image = Image.frombytes(\n",
    "                heif_file.mode, heif_file.size, heif_file.data, \"raw\"\n",
    "            )\n",
    "        else:\n",
    "            image = Image.open(file_path)\n",
    "\n",
    "        image = image.convert(\"RGB\")\n",
    "\n",
    "        base_name = os.path.basename(file_path)\n",
    "        new_file_path = f\"{source_folder}{os.path.splitext(base_name)[0]}.jpg\"\n",
    "        os.remove(file_path)\n",
    "        image.save(new_file_path, \"JPEG\")\n",
    "        print(f\"Converted {file_path} to {new_file_path}\")\n",
    "\n",
    "        return new_file_path\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to convert {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_images_from_df(df, source_folder):\n",
    "    new_images = []\n",
    "    for _, row in df.iterrows():\n",
    "        file_path = row[\"File Path\"]\n",
    "        converted_path = convert_to_jpg(file_path, source_folder)\n",
    "        if converted_path:\n",
    "            new_images.append(converted_path)\n",
    "    return new_images\n",
    "\n",
    "\n",
    "def extract_frame_from_mp4(video_path, output_folder, frame_number=0):\n",
    "    try:\n",
    "        video = cv2.VideoCapture(video_path)\n",
    "        \n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frame_number)\n",
    "        success, frame = video.read()\n",
    "        video.release()\n",
    "\n",
    "        if not success:\n",
    "            print(f\"Failed to extract frame from {video_path}\")\n",
    "            return None\n",
    "        \n",
    "        base_name = os.path.basename(video_path)\n",
    "        output_file = os.path.join(output_folder, f\"{os.path.splitext(base_name)[0]}.jpg\")\n",
    "        \n",
    "        os.remove(video_path)\n",
    "        cv2.imwrite(output_file, frame)\n",
    "        print(f\"Extracted frame from {video_path} and saved to {output_file}\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {video_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_mp4_to_jpg(mp4_df, output_folder):\n",
    "    jpg_files = []\n",
    "    for _, row in mp4_df.iterrows():\n",
    "        video_path = row[\"File Path\"]\n",
    "        jpg_path = extract_frame_from_mp4(video_path, output_folder)\n",
    "        if jpg_path:\n",
    "            jpg_files.append(jpg_path)\n",
    "    return jpg_files\n",
    "\n",
    "def list_non_jpg_images(folder_path, image_extensions):\n",
    "    non_jpg_files = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            _, extension = os.path.splitext(filename)\n",
    "            if extension.lower() in image_extensions:\n",
    "                non_jpg_files.append(file_path)\n",
    "    return non_jpg_files\n",
    "\n",
    "extensions_in_folder = list_extensions(source_folder)\n",
    "\n",
    "extensions_in_folder.discard(\".jpg\")\n",
    "if \".mp4\" in extensions_in_folder:\n",
    "    mp4_Extension = \".mp4\"\n",
    "\n",
    "print(\"Extensions found in the folder:\")\n",
    "for ext in sorted(extensions_in_folder):\n",
    "    print(ext if ext else \"No extension (e.g., hidden or extensionless files)\")\n",
    "\n",
    "non_jpg_images = list_non_jpg_images(source_folder, extensions_in_folder)\n",
    "img_not_jpg_df = pd.DataFrame(non_jpg_images, columns=[\"File Path\"])\n",
    "\n",
    "if \".mp4\" in extensions_in_folder:\n",
    "    mp4_images = list_non_jpg_images(source_folder, mp4_Extension)\n",
    "    if mp4_images:\n",
    "        mp4_img_df = pd.DataFrame(mp4_images, columns=[\"File Path\"])\n",
    "    \n",
    "convert_images_from_df(img_not_jpg_df, output_folder)\n",
    "if \".mp4\" in extensions_in_folder:\n",
    "    jpg_files = process_mp4_to_jpg(mp4_img_df, output_folder)\n",
    "    mp4_to_jpg_df = pd.DataFrame(jpg_files, columns=[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.2.2+cu118\n",
      "Torchvision version: 0.17.2+cu118\n",
      "CUDA available: True\n",
      "CUDA device: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torchvision.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")\n",
    "print(f\"Using device: {device}\")\n",
    "mtcnn = MTCNN(keep_all=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_mtcnn(img, img_index, cropped_faces):\n",
    "    try:\n",
    "        correct_rotation = 0\n",
    "        highest_prob = 0.0\n",
    "        confidence_threshold = 0.82\n",
    "        length = 4\n",
    "        horizontal_preffered_dimensions = (1008, 756)\n",
    "        vertical_preffered_dimensions = (756, 1008)\n",
    "        valid_boxes = []\n",
    "        best_probs = []\n",
    "        found_landmarks  = []\n",
    "        #print(img.shape)\n",
    "        for i in range(length):\n",
    "            empty_box = False\n",
    "            degrees = 90 * i\n",
    "            rotated_img = img\n",
    "\n",
    "            if degrees == 90:\n",
    "                rotated_img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "            elif degrees == 180:\n",
    "                rotated_img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "            elif degrees == 270:\n",
    "                rotated_img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "            height, width, _ = rotated_img.shape\n",
    "\n",
    "            if width > height: \n",
    "                scale = min(horizontal_preffered_dimensions[0] / width, horizontal_preffered_dimensions[1] / height)\n",
    "            else:\n",
    "                scale = min(vertical_preffered_dimensions[0] / width, vertical_preffered_dimensions[1] / height)\n",
    "\n",
    "            new_width = int(width * scale)\n",
    "            new_height = int(height * scale)\n",
    "\n",
    "            resized_img = cv2.resize(rotated_img, (new_width, new_height))\n",
    "            #resized_img = cv2.resize(rotated_img, (width, height))\n",
    "            #print(resized_img.shape)\n",
    "                \n",
    "            boxes, probs, landmarks = mtcnn.detect(resized_img, landmarks=True)\n",
    "\n",
    "            if boxes is None or probs is None or landmarks is None:\n",
    "                empty_box = True\n",
    "                boxes, landmarks = [], []\n",
    "\n",
    "            #print(f\"Image index {img_index}: Detection probabilities - {probs}\")\n",
    "            rotated_img = cv2.cvtColor(rotated_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if not empty_box:\n",
    "                filtered = [\n",
    "                    (box, prob, landmark)\n",
    "                    for box, prob, landmark in zip(boxes, probs, landmarks)\n",
    "                    if prob >= confidence_threshold\n",
    "                    #if Valid_Landmarks(box, landmark)\n",
    "                ]\n",
    "                boxes, probs, landmarks = zip(*filtered) if filtered else ([], [], [])\n",
    "                boxes = sorted(boxes, key=lambda box: box[0])\n",
    "\n",
    "                for prob in probs:\n",
    "                    if prob > highest_prob:\n",
    "                        highest_prob = prob\n",
    "                        best_probs = probs\n",
    "                        valid_boxes = boxes\n",
    "                        found_landmarks = landmarks\n",
    "                        correct_rotation = degrees\n",
    "\n",
    "        if correct_rotation == 90:\n",
    "            img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "        elif correct_rotation == 180:\n",
    "            img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "        elif correct_rotation == 270:\n",
    "            img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "            \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        for box, landmark, prob in zip(valid_boxes, found_landmarks, best_probs):\n",
    "            #print(f\"Image index {img_index}: Detection probabilities - {prob}\")    \n",
    "            \n",
    "            height, width, _ = img.shape\n",
    "            x1, y1, x2, y2 = [int(coord) for coord in box]\n",
    "            \n",
    "            x1 = int(x1 / scale)\n",
    "            y1 = int(y1 / scale)\n",
    "            x2 = int(x2 / scale)\n",
    "            y2 = int(y2 / scale)\n",
    "\n",
    "            x1 = max(0, min(x1, width - 1))\n",
    "            y1 = max(0, min(y1, height - 1))\n",
    "            x2 = max(0, min(x2, width - 1))\n",
    "            y2 = max(0, min(y2, height - 1))\n",
    "\n",
    "            cropped_face = img[y1:y2, x1:x2]\n",
    "            cropped_faces.append(cropped_face)\n",
    "\n",
    "            #cropped_face = cv2.cvtColor(cropped_face, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            #cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            #print(f\"Face landmarks: {landmark}\")\n",
    "            for point in landmark:\n",
    "                px, py = int(point[0]), int(point[1])\n",
    "                #cv2.circle(img, (px, py), 5, (255, 0, 0), -1)  # Draw landmarks\n",
    "\n",
    "            #plt.imshow(cropped_face)\n",
    "            #plt.axis(\"off\")\n",
    "            #plt.show()\n",
    "\n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        #plt.imshow(img)\n",
    "        #plt.axis(\"off\")\n",
    "        #plt.show()\n",
    "\n",
    "        Cropped_FilePath = \"CroppedTestImg\"\n",
    "        os.makedirs(Cropped_FilePath, exist_ok=True)\n",
    "\n",
    "        return len(valid_boxes)\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting faces in image index {img_index}: {e}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/99 images\n",
      "Processed 2/99 images\n",
      "Processed 3/99 images\n",
      "Processed 4/99 images\n",
      "Processed 5/99 images\n",
      "Processed 6/99 images\n",
      "Processed 7/99 images\n",
      "Processed 8/99 images\n",
      "Processed 9/99 images\n",
      "Processed 10/99 images\n",
      "Processed 11/99 images\n",
      "Processed 12/99 images\n",
      "Processed 13/99 images\n",
      "Processed 14/99 images\n",
      "Processed 15/99 images\n",
      "Processed 16/99 images\n",
      "Processed 17/99 images\n",
      "Processed 18/99 images\n",
      "Processed 19/99 images\n",
      "Processed 20/99 images\n",
      "Processed 21/99 images\n",
      "Processed 22/99 images\n",
      "Processed 23/99 images\n",
      "Processed 24/99 images\n",
      "Processed 25/99 images\n",
      "Processed 26/99 images\n",
      "Processed 27/99 images\n",
      "Processed 28/99 images\n",
      "Processed 29/99 images\n",
      "Processed 30/99 images\n",
      "Processed 31/99 images\n",
      "Processed 32/99 images\n",
      "Processed 33/99 images\n",
      "Processed 34/99 images\n",
      "Processed 35/99 images\n",
      "Processed 36/99 images\n",
      "Processed 37/99 images\n",
      "Processed 38/99 images\n",
      "Processed 39/99 images\n",
      "Processed 40/99 images\n",
      "Processed 41/99 images\n",
      "Processed 42/99 images\n",
      "Processed 43/99 images\n",
      "Processed 44/99 images\n",
      "Processed 45/99 images\n",
      "Processed 46/99 images\n",
      "Processed 47/99 images\n",
      "Processed 48/99 images\n",
      "Processed 49/99 images\n",
      "Processed 50/99 images\n",
      "Processed 51/99 images\n",
      "Processed 52/99 images\n",
      "Processed 53/99 images\n",
      "Processed 54/99 images\n",
      "Processed 55/99 images\n",
      "Processed 56/99 images\n",
      "Processed 57/99 images\n",
      "Processed 58/99 images\n",
      "Processed 59/99 images\n",
      "Processed 60/99 images\n",
      "Processed 61/99 images\n",
      "Processed 62/99 images\n",
      "Processed 63/99 images\n",
      "Processed 64/99 images\n",
      "Processed 65/99 images\n",
      "Processed 66/99 images\n",
      "Processed 67/99 images\n",
      "Processed 68/99 images\n",
      "Processed 69/99 images\n",
      "Processed 70/99 images\n",
      "Processed 71/99 images\n",
      "Processed 72/99 images\n",
      "Processed 73/99 images\n",
      "Processed 74/99 images\n",
      "Processed 75/99 images\n",
      "Processed 76/99 images\n",
      "Processed 77/99 images\n",
      "Processed 78/99 images\n",
      "Processed 79/99 images\n",
      "Processed 80/99 images\n",
      "Processed 81/99 images\n",
      "Processed 82/99 images\n",
      "Processed 83/99 images\n",
      "Processed 84/99 images\n",
      "Processed 85/99 images\n",
      "Processed 86/99 images\n",
      "Processed 87/99 images\n",
      "Processed 88/99 images\n",
      "Processed 89/99 images\n",
      "Processed 90/99 images\n",
      "Processed 91/99 images\n",
      "Processed 92/99 images\n",
      "Processed 93/99 images\n",
      "Processed 94/99 images\n",
      "Processed 95/99 images\n",
      "Processed 96/99 images\n",
      "Processed 97/99 images\n",
      "Processed 98/99 images\n",
      "Processed 99/99 images\n",
      "faces found: 178\n",
      "None faces found: 4\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "Cropped_FilePath = \"CroppedTestImg\"\n",
    "CroppedImg_filepaths = []\n",
    "bad_detect = pd.DataFrame()\n",
    "\n",
    "bad = 0\n",
    "good = 0\n",
    "\n",
    "length = len(test_data)\n",
    "for i in range(length):\n",
    "\n",
    "    cropped_faces = []\n",
    "    position = i + start\n",
    "    img = cv2.imread(test_data[position])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    detected = detect_faces_mtcnn(img, position, cropped_faces)\n",
    "\n",
    "    img_name = os.path.basename(test_data[position])\n",
    "    img_name = os.path.splitext(img_name)[0]\n",
    "\n",
    "    for d in range(detected):\n",
    "        Img_FilePath = os.path.join(Cropped_FilePath, f\"{img_name}_{d}.jpg\")\n",
    "        CroppedImg_filepaths.append(Img_FilePath)\n",
    "        cv2.imwrite(Img_FilePath, cropped_faces[d])\n",
    "        good += 1\n",
    "\n",
    "    if detected == 0:\n",
    "        bad_detect = pd.concat([bad_detect, pd.DataFrame({\n",
    "            'image': [test_data[position]],\n",
    "            'guess': ['nothing']\n",
    "        })], ignore_index=True)\n",
    "        bad += 1\n",
    "\n",
    "    print(f\"Processed {i+1}/{length} images\")\n",
    "\n",
    "print(f\"faces found: {good}\")\n",
    "print(f\"None faces found: {bad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_with_padding(input_dir, output_dir, target_size=(160, 160)):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for file in tqdm(files, desc=f\"Processing images in {root}\"):\n",
    "            try:\n",
    "                input_path = os.path.join(root, file)\n",
    "                output_subdir = os.path.join(output_dir, os.path.relpath(root, input_dir))\n",
    "                os.makedirs(output_subdir, exist_ok=True)\n",
    "\n",
    "                output_path = os.path.join(output_subdir, file)\n",
    "\n",
    "                with Image.open(input_path) as img:\n",
    "                    img = img.convert(\"RGB\")\n",
    "\n",
    "                    if img.width < target_size[0] and img.height < target_size[1]:\n",
    "                        scale_factor = min(\n",
    "                            target_size[0] / img.width,\n",
    "                            target_size[1] / img.height\n",
    "                        )\n",
    "                        new_width = int(img.width * scale_factor)\n",
    "                        new_height = int(img.height * scale_factor)\n",
    "                        img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "\n",
    "                    else:\n",
    "                        img.thumbnail(target_size, Image.Resampling.LANCZOS)\n",
    "\n",
    "                    new_img = Image.new(\"RGB\", target_size, (0, 0, 0))\n",
    "\n",
    "                    offset_x = (target_size[0] - img.width) // 2\n",
    "                    offset_y = (target_size[1] - img.height) // 2\n",
    "                    new_img.paste(img, (offset_x, offset_y))\n",
    "\n",
    "                    new_img.save(output_path)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images in CroppedTestImg: 100%|██████████| 178/178 [00:01<00:00, 104.76it/s]\n"
     ]
    }
   ],
   "source": [
    "input_dir = \"CroppedTestImg\"\n",
    "output_dir = \"CroppedTestImg_resized_160\"\n",
    "resize_with_padding(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: {0: 'Akif', 1: 'Alper', 2: 'Bart', 3: 'Daiane', 4: 'Florian', 5: 'Konrad', 6: 'Lasse', 7: 'Matthias', 8: 'Michiel', 9: 'Nelli', 10: 'Raul', 11: 'Senne', 12: 'Seppe', 13: 'Youssef'}\n",
      "[45, 427, 513, 770]\n",
      "Predictions saved to FinalResults_UT_54_160.csv\n"
     ]
    }
   ],
   "source": [
    "facenet = FaceNet()\n",
    "base_model = facenet.model\n",
    "\n",
    "with open(\"Labels_faces.pickle\", 'rb') as f:\n",
    "    class_labels = pickle.load(f)\n",
    "    class_labels = {n: i for i, n in class_labels.items()}\n",
    "print(f\"Class labels: {class_labels}\")\n",
    "\n",
    "num_classes = len(class_labels)\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "fine_tuned_model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "fine_tuned_model.load_weights('fine_tuned_model_weights.h5')\n",
    "\n",
    "testset_dir = \"CroppedTestImg_resized_160\"\n",
    "original_testset_dir = \"testset/testset\"\n",
    "output_csv = \"FinalResults_UT_54_160.csv\"\n",
    "\n",
    "def preprocess_image(img_path, target_size=(160, 160)):\n",
    "    \"\"\"\n",
    "    Preprocess a single image.\n",
    "    \"\"\"\n",
    "    img = load_img(img_path, target_size=target_size)\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    return np.expand_dims(img_array, axis=0)\n",
    "\n",
    "results = {}\n",
    "Grouping_number = []\n",
    "Current_number = 0\n",
    "\n",
    "for file_name in os.listdir(testset_dir):\n",
    "    prefix = file_name.split('_')[0]\n",
    "    img_number = prefix.lstrip(\"0\")\n",
    "    if (img_number not in Grouping_number):\n",
    "        Grouping_number.append(img_number)\n",
    "        results[img_number] = []\n",
    "        Current_number = img_number\n",
    "        #print(\"new number\")\n",
    "\n",
    "    image_path = os.path.join(testset_dir, file_name)\n",
    "    #print(image_path)\n",
    "\n",
    "    if not os.path.isfile(image_path):\n",
    "        #print(\"not a file\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        preprocessed_img = preprocess_image(image_path)\n",
    "\n",
    "        predictions = fine_tuned_model.predict(preprocessed_img, verbose=0)\n",
    "        predicted_class = np.argmax(predictions)\n",
    "        predicted_label = class_labels[predicted_class].lower()\n",
    "\n",
    "        results[Current_number].append(predicted_label)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "        results[Current_number].append(\"error\")\n",
    "\n",
    "#print(results)\n",
    "\n",
    "all_image_numbers = sorted({int(file.split('.')[0]) for file in os.listdir(original_testset_dir) if file.lower().endswith(('.jpg'))})\n",
    "#print(all_image_numbers)\n",
    "predicted_image_numbers = sorted(results.keys(), key=int)\n",
    "predicted_image_numbers = [int(num) for num in predicted_image_numbers]\n",
    "#print(predicted_image_numbers)\n",
    "missing_image_numbers = [num for num in all_image_numbers if num not in predicted_image_numbers]\n",
    "print(missing_image_numbers)\n",
    "\n",
    "for missing_number in sorted(missing_image_numbers):\n",
    "    results[missing_number] = [\"nothing\"]\n",
    "\n",
    "with open(output_csv, mode=\"w\", newline=\"\") as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow([\"image\", \"label_name\"])\n",
    "\n",
    "    for image_number in sorted(results.keys(), key=int):\n",
    "        labels_in_order = \";\".join(results[image_number])\n",
    "        csv_writer.writerow([image_number, labels_in_order])\n",
    "\n",
    "print(f\"Predictions saved to {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
