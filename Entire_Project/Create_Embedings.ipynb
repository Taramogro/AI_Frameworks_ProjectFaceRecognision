{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Senne\\AI_Frameworks\\Project\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Senne\\AI_Frameworks\\Project\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from PIL import Image, ImageOps, ImageFilter, ImageEnhance\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import cv2\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cropped_50\\Akif\n",
      "Cropped_50\\Alper\n",
      "Cropped_50\\Bart\n",
      "Cropped_50\\Daiane\n",
      "Cropped_50\\Florian\n",
      "Cropped_50\\Konrad\n",
      "Cropped_50\\Lasse\n",
      "Cropped_50\\Matthias\n",
      "Cropped_50\\Michiel\n",
      "Cropped_50\\Nelli\n",
      "Cropped_50\\Raul\n",
      "Cropped_50\\Senne\n",
      "Cropped_50\\Seppe\n",
      "Cropped_50\\Youssef\n",
      "   id label                                          embedding\n",
      "0   0  Akif  [-0.07321271300315857, -0.015161692164838314, ...\n",
      "1   0  Akif  [-0.04495805874466896, -0.03904763609170914, 0...\n",
      "2   0  Akif  [-0.06774255633354187, 0.03536646068096161, 0....\n",
      "3   0  Akif  [-0.06966079771518707, 0.012463579885661602, 0...\n",
      "4   0  Akif  [-0.08187726140022278, 0.07773150503635406, 0....\n"
     ]
    }
   ],
   "source": [
    "DIR = \"Cropped_50\"\n",
    "\n",
    "shape_predictor_path = \"shape_predictor_68_face_landmarks.dat\"\n",
    "face_rec_model_path = \"dlib_face_recognition_resnet_model_v1.dat\"\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "sp = dlib.shape_predictor(shape_predictor_path)\n",
    "facerec = dlib.face_recognition_model_v1(face_rec_model_path)\n",
    "\n",
    "label_ids = {}\n",
    "current_id = 0\n",
    "embeddings_list = []\n",
    "\n",
    "for person_folder in os.listdir(DIR):\n",
    "    person_path = os.path.join(DIR, person_folder)\n",
    "    print(person_path)\n",
    "    if os.path.isdir(person_path) and person_folder != 'default':\n",
    "        for image_file in os.listdir(person_path):\n",
    "            img_path = os.path.join(person_path, image_file)\n",
    "            #print(img_path)\n",
    "            img_label = os.path.basename(person_path)\n",
    "\n",
    "            if img_label not in label_ids:\n",
    "                label_ids[img_label] = current_id\n",
    "                current_id += 1\n",
    "            id_ = label_ids[img_label]\n",
    "\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img_cv = np.array(img)\n",
    "\n",
    "            dets = detector(img_cv, 1)\n",
    "            \n",
    "            for k, d in enumerate(dets):\n",
    "                shape = sp(img_cv, d)\n",
    "                \n",
    "                embedding = facerec.compute_face_descriptor(img_cv, shape)\n",
    "                embedding = np.array(embedding)\n",
    "\n",
    "                embeddings_list.append([id_, img_label, embedding])\n",
    "\n",
    "df = pd.DataFrame(embeddings_list, columns=['id', 'label', 'embedding'])\n",
    "\n",
    "df.to_pickle(\"embeddings_C_54.pkl\")\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Intra-person Similarity: 0.9533899585932866\n",
      "Average Inter-person Similarity: 0.8528155944917816\n"
     ]
    }
   ],
   "source": [
    "def evaluate_embeddings(df):\n",
    "    intra_similarities = []\n",
    "    inter_similarities = []\n",
    "\n",
    "    for label in df['label'].unique():\n",
    "        embeddings = df[df['label'] == label]['embedding'].tolist()\n",
    "\n",
    "        for i in range(len(embeddings)):\n",
    "            for j in range(i+1, len(embeddings)):\n",
    "                similarity = cosine_similarity([embeddings[i]], [embeddings[j]])[0][0]\n",
    "                intra_similarities.append(similarity)\n",
    "\n",
    "        for other_label in df['label'].unique():\n",
    "            if other_label != label:\n",
    "                other_embeddings = df[df['label'] == other_label]['embedding'].tolist()\n",
    "                for e1 in embeddings:\n",
    "                    for e2 in other_embeddings:\n",
    "                        similarity = cosine_similarity([e1], [e2])[0][0]\n",
    "                        inter_similarities.append(similarity)\n",
    "\n",
    "    return np.mean(intra_similarities), np.mean(inter_similarities)\n",
    "\n",
    "intra_similarity, inter_similarity = evaluate_embeddings(df)\n",
    "\n",
    "print(f\"Average Intra-person Similarity: {intra_similarity}\")\n",
    "print(f\"Average Inter-person Similarity: {inter_similarity}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
