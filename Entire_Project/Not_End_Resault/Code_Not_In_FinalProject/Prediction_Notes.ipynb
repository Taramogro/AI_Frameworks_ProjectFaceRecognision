{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_mtcnn(img, img_index, cropped_faces):\n",
    "    try:\n",
    "        correct_rotation = 0\n",
    "        correct_box_length = []\n",
    "        highest_prob = 0.0 \n",
    "        for i in range(4):\n",
    "            empty_box = False\n",
    "            degrees = 90 * i\n",
    "            rotated_img = img\n",
    "            if degrees == 90:\n",
    "                rotated_img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "            elif degrees == 180:\n",
    "                rotated_img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "            elif degrees == 270:\n",
    "                rotated_img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            height, width, _ = rotated_img.shape\n",
    "            #resized_img = cv2.resize(img, (width // 6, height // 6))\n",
    "            resized_img = cv2.resize(rotated_img, (width, height))\n",
    "            confidence_threshold = 0.83\n",
    "            boxes, probs = mtcnn.detect(resized_img)\n",
    "            rotated_img = cv2.cvtColor(rotated_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if boxes is None or probs is None:\n",
    "                empty_box = True\n",
    "                boxes = []\n",
    "\n",
    "            #print(boxes)\n",
    "            print(probs)\n",
    "\n",
    "            if empty_box == False:\n",
    "                boxes = [box for box, prob in zip(boxes, probs) if prob >= confidence_threshold]\n",
    "                boxes = sorted(boxes, key=lambda box: box[0])\n",
    "\n",
    "                for box in boxes:\n",
    "                    for prob in probs:\n",
    "                        if prob > highest_prob:\n",
    "                            highest_prob = prob\n",
    "                            correct_box_length = boxes\n",
    "                            correct_rotation = degrees\n",
    "                    #print(len(correct_box_length))\n",
    "                    x1, y1, x2, y2 = [int(coord) for coord in box]\n",
    "\n",
    "                    #x1, y1, x2, y2 = x1 * 6, y1 * 6, x2 * 6, y2 * 6\n",
    "                    height, width, _ = rotated_img.shape\n",
    "\n",
    "                    x1 = max(0, min(x1, width - 1))\n",
    "                    y1 = max(0, min(y1, height - 1))\n",
    "                    x2 = max(0, min(x2, width - 1))\n",
    "                    y2 = max(0, min(y2, height - 1))\n",
    "\n",
    "                    cropped_face = rotated_img[y1:y2, x1:x2]\n",
    "                    cropped_faces.append(cropped_face)\n",
    "\n",
    "                    cropped_face = cv2.cvtColor(cropped_face, cv2.COLOR_BGR2RGB)\n",
    "                    if len(cropped_face.shape) == 3:\n",
    "                        plt.imshow(cropped_face)\n",
    "                        plt.axis('off')\n",
    "                        plt.show()\n",
    "                    else:\n",
    "                        plt.imshow(cropped_face, cmap='gray')\n",
    "                        plt.axis('off')\n",
    "                        plt.show()\n",
    "                    \n",
    "                    cv2.rectangle(rotated_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        if correct_rotation == 90:\n",
    "            img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "        elif correct_rotation == 180:\n",
    "            img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "        elif correct_rotation == 270:\n",
    "            img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        if len(img.shape) == 3:\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "\n",
    "        Cropped_FilePath = \"C:/Users/Senne/AI_Frameworks/Project/CroppedTestImg\"\n",
    "        os.makedirs(Cropped_FilePath, exist_ok=True)\n",
    "\n",
    "        return len(correct_box_length)\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting faces in image index {img_index}: {e}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Valid_Landmarks(box, Landmark):\n",
    "    hight = box[3] - box[1]\n",
    "    width = box[2] - box[0]\n",
    "    left_eye, right_eye, nose, left_mouth, right_mouth = Landmark\n",
    "\n",
    "    eye_distance = np.linalg.norm(np.array(left_eye) - np.array(right_eye))\n",
    "    nose_to_mouth_distance = np.linalg.norm(np.array(nose) - (np.array(left_mouth) + np.array(right_mouth)) / 2)\n",
    "\n",
    "    #print(f\"eye distance: {eye_distance}\")\n",
    "    #print(f\"nose to mouth distance: {nose_to_mouth_distance}\")\n",
    "\n",
    "    if eye_distance < 10:\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "recognizer.read(\"C:/Users/Senne/AI_Frameworks/Project/Models/Trainer_LBHF.yml\")\n",
    "dir = \"C:/Users/Senne/AI_Frameworks/Project/CroppedTestImg\"\n",
    "\n",
    "results_FileNames = []\n",
    "\n",
    "\n",
    "desired_width = 500\n",
    "desired_height = 550\n",
    "\n",
    "P_name = {\"personName\": 1}\n",
    "with open(\"Labels_faces.pickle\", 'rb') as f:\n",
    "    P_name = pickle.load(f)\n",
    "    P_name = {n:i for i,n in P_name.items()}\n",
    "\n",
    "total = 0\n",
    "\n",
    "results = pd.DataFrame()\n",
    "results = pd.concat([results, bad_detect], ignore_index=True)\n",
    "\n",
    "for image_file in os.listdir(dir):\n",
    "    Images = []\n",
    "    total += 1\n",
    "    img_path = os.path.join(dir, image_file)\n",
    "\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    id_, conf = recognizer.predict(img)\n",
    "\n",
    "    print(P_name.get(id_))\n",
    "    print(conf)\n",
    "\n",
    "\n",
    "    if conf >= 45 or conf <= 85:\n",
    "        predicted_label = P_name.get(id_, \"Unknown\")\n",
    "    \n",
    "    results = pd.concat([results, pd.DataFrame({\n",
    "        'image': [img_path],\n",
    "        'guess': [predicted_label]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "    if total % 25 == 0:\n",
    "        print(f\"Processed {total} images\")\n",
    "\n",
    "results = results.sort_values(by='image', key=lambda col: col.map(os.path.basename)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embeddings = pd.read_pickle(\"C:/Users/Senne/AI_Frameworks/Project/embeddings.pkl\")\n",
    "\n",
    "with open(\"Labels_faces.pickle\", 'rb') as f:\n",
    "    P_name = pickle.load(f)\n",
    "    P_name = {n: i for i, n in P_name.items()}\n",
    "\n",
    "dir = \"C:/Users/Senne/AI_Frameworks/Project/CroppedTestImg\"\n",
    "\n",
    "shape_predictor_path = \"C:/Users/Senne/AI_Frameworks/Project/Models/shape_predictor_68_face_landmarks.dat\"\n",
    "face_rec_model_path = \"C:/Users/Senne/AI_Frameworks/Project/Models/dlib_face_recognition_resnet_model_v1.dat\"\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "side_detector = dlib.get_frontal_face_detector()\n",
    "sp = dlib.shape_predictor(shape_predictor_path)\n",
    "facerec = dlib.face_recognition_model_v1(face_rec_model_path)\n",
    "\n",
    "results = pd.DataFrame()\n",
    "\n",
    "for image_file in os.listdir(dir):\n",
    "    img_path = os.path.join(dir, image_file)\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    dets = detector(img_rgb, 1)\n",
    "    \n",
    "    if len(dets) == 0:\n",
    "        dets = side_detector(img_rgb, 1)\n",
    "    \n",
    "    if len(dets) == 0:\n",
    "        continue\n",
    "\n",
    "    for k, d in enumerate(dets):\n",
    "        shape = sp(img_rgb, d)\n",
    "        \n",
    "        face_chip = dlib.get_face_chip(img_rgb, shape)\n",
    "\n",
    "        face_descriptor = facerec.compute_face_descriptor(face_chip)\n",
    "\n",
    "        embedding = np.array(face_descriptor).reshape(1, -1)\n",
    "\n",
    "        similarities = []\n",
    "        for stored_embedding in df_embeddings['embedding']:\n",
    "            stored_embedding = np.array(stored_embedding).reshape(1, -1)\n",
    "            similarity = cosine_similarity(embedding, stored_embedding)\n",
    "            similarities.append(similarity[0][0])\n",
    "\n",
    "        max_similarity_index = np.argmax(similarities)\n",
    "        best_match_id = df_embeddings.iloc[max_similarity_index]['id']\n",
    "        predicted_label = P_name.get(best_match_id, \"Unknown\")\n",
    "        confidence = similarities[max_similarity_index]\n",
    "\n",
    "        results = pd.concat([results, pd.DataFrame({\n",
    "            'image': [img_path],\n",
    "            'guess': [predicted_label],\n",
    "            'confidence': confidence,\n",
    "        })], ignore_index=True)\n",
    "\n",
    "        print(f\"Processed: {image_file} - Predicted: {predicted_label} - Similarity: {confidence:.4f}\")\n",
    "\n",
    "results = results.sort_values(by='image', key=lambda col: col.map(os.path.basename)).reset_index(drop=True)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_FileNames = []\n",
    "results_FileNames = []\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    person_path = test_data[i]\n",
    "    File_name = os.path.splitext(os.path.basename(person_path))[0]\n",
    "    File_name = File_name.lstrip('0')\n",
    "    File_name = File_name.split('_')[0]\n",
    "    test_data_FileNames.append(File_name)\n",
    "\n",
    "for i in range(len(results)):\n",
    "    person_path = results['image'][i]\n",
    "    File_name = os.path.splitext(os.path.basename(person_path))[0]\n",
    "    File_name = File_name.lstrip('0')\n",
    "    File_name = File_name.split('_')[0]\n",
    "    results_FileNames.append(File_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
