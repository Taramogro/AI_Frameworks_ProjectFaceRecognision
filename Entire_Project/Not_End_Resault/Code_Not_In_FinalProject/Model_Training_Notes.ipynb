{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom_image(image, zoom_factor=1.2):\n",
    "    width, height = image.size\n",
    "    new_width = int(width * zoom_factor)\n",
    "    new_height = int(height * zoom_factor)\n",
    "    zoomed_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "    return zoomed_image.crop((0, 0, width, height))\n",
    "\n",
    "def add_noise(image):\n",
    "    image_array = np.array(image)\n",
    "    row, col = image_array.shape\n",
    "    gauss = np.random.normal(0, 25, (row, col))\n",
    "    noisy_image = np.array(np.clip(image_array + gauss, 0, 255), dtype=np.uint8)\n",
    "    return Image.fromarray(noisy_image)\n",
    "\n",
    "def shear_image(image, shear_factor=0.2):\n",
    "    width, height = image.size\n",
    "    matrix = [1, shear_factor, 0, shear_factor, 1, 0]\n",
    "    return image.transform((width, height), Image.AFFINE, matrix)\n",
    "\n",
    "def random_crop(image, crop_size=(400, 400)):\n",
    "    width, height = image.size\n",
    "    crop_width, crop_height = crop_size\n",
    "    x_offset = random.randint(0, width - crop_width)\n",
    "    y_offset = random.randint(0, height - crop_height)\n",
    "    return image.crop((x_offset, y_offset, x_offset + crop_width, y_offset + crop_height))\n",
    "\n",
    "def perspective_transform(image):\n",
    "    image_array = np.array(image)\n",
    "    rows, cols = image_array.shape\n",
    "    pts1 = np.float32([[50,50], [200,50], [50,200], [200,200]])\n",
    "    pts2 = np.float32([[10,100], [200,50], [100,250], [210,250]])\n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    return cv2.warpPerspective(image_array, M, (cols, rows))\n",
    "\n",
    "def random_blur(image):\n",
    "    return image.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.1, 2.0)))\n",
    "\n",
    "def adjust_brightness(image, factor=1.2):\n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "def augment_image(image):\n",
    "    augmented_images = []\n",
    "    augmented_images.append(image)\n",
    "    augmented_images.append(ImageOps.mirror(image))\n",
    "    augmented_images.append(ImageOps.flip(image))\n",
    "    augmented_images.append(image.rotate(random.randint(-30, 30), expand=True))\n",
    "    augmented_images.append(zoom_image(image))\n",
    "    augmented_images.append(add_noise(image))\n",
    "    augmented_images.append(shear_image(image))\n",
    "    augmented_images.append(random_crop(image))\n",
    "    augmented_images.append(random_blur(image))\n",
    "    augmented_images.append(adjust_brightness(image, random.uniform(0.8, 1.2)))\n",
    "    return augmented_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"Cropped\"\n",
    "save_dir = \"Padding\"\n",
    "\n",
    "model_path = \"Trainer_LBHF.yml\"\n",
    "\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "#recognizer = cv2.face.EigenFaceRecognizer_create()\n",
    "#recognizer = cv2.face.FisherFaceRecognizer_create()\n",
    "\n",
    "current_id = 0\n",
    "label_ids = {}\n",
    "Names = []\n",
    "y_labels = []\n",
    "x_train = []\n",
    "\n",
    "desired_width = 500\n",
    "desired_height = 550\n",
    "\n",
    "for person_folder in os.listdir(DIR):\n",
    "    person_path = os.path.join(DIR, person_folder)\n",
    "    if os.path.isdir(person_path) and person_folder != 'default':\n",
    "        for image_file in os.listdir(person_path):\n",
    "            img_path = os.path.join(person_path, image_file)\n",
    "            img_label = os.path.basename(person_path)\n",
    "\n",
    "            if not img_label in label_ids:\n",
    "                label_ids[img_label] = current_id\n",
    "                current_id += 1\n",
    "            id_ = label_ids[img_label]\n",
    "\n",
    "            pill_img = Image.open(img_path).convert(\"L\")\n",
    "\n",
    "            width, height = pill_img.size\n",
    "            if width >= desired_width and height >= desired_height:\n",
    "                img_re = pill_img.resize((desired_width, desired_height), Image.Resampling.LANCZOS)\n",
    "            else:\n",
    "                top = (desired_height - height) // 2\n",
    "                bottom = desired_height - height - top\n",
    "                left = (desired_width - width) // 2\n",
    "                right = desired_width - width - left\n",
    "\n",
    "                img_re = Image.new('L', (desired_width, desired_height), (0))\n",
    "                img_re.paste(pill_img, (left, top)) \n",
    "\n",
    "                img_re = img_re.resize((desired_width, desired_height), Image.Resampling.LANCZOS)\n",
    "                \n",
    "            img_re.save(os.path.join(save_dir, f\"original_{person_folder}_{image_file}\"))\n",
    "\n",
    "            img_array = np.array(img_re, \"uint8\")\n",
    "            x_train.append(img_array)\n",
    "            y_labels.append(id_)\n",
    "            \n",
    "            augmented_images = augment_image(img_re)\n",
    "            \n",
    "            for aug_img in augmented_images:\n",
    "                img_array = np.array(aug_img, \"float32\") / 255.0\n",
    "                x_train.append(img_array)\n",
    "                y_labels.append(id_)\n",
    "\n",
    "x_train, y_labels = shuffle(x_train, y_labels, random_state=42)\n",
    "\n",
    "with open(\"Labels_faces.pickle\", 'wb') as f:\n",
    "    pickle.dump(label_ids, f)\n",
    "\n",
    "recognizer.train(x_train, np.array(y_labels))\n",
    "recognizer.save(model_path)\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Model successfully saved to {model_path}\")\n",
    "else:\n",
    "    print(f\"Failed to save the model to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import dlib\n",
    "from sklearn.svm import SVC\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "DIR = \"Cropped_50\"\n",
    "\n",
    "shape_predictor_path = \"shape_predictor_68_face_landmarks.dat\"\n",
    "face_rec_model_path = \"dlib_face_recognition_resnet_model_v1.dat\"\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "sp = dlib.shape_predictor(shape_predictor_path)\n",
    "facerec = dlib.face_recognition_model_v1(face_rec_model_path)\n",
    "\n",
    "label_ids = {}\n",
    "current_id = 0\n",
    "embeddings_list = []\n",
    "labels = []\n",
    "\n",
    "for person_folder in os.listdir(DIR):\n",
    "    person_path = os.path.join(DIR, person_folder)\n",
    "    if os.path.isdir(person_path) and person_folder != 'default':\n",
    "        for image_file in os.listdir(person_path):\n",
    "            img_path = os.path.join(person_path, image_file)\n",
    "            img_label = os.path.basename(person_path)\n",
    "\n",
    "            if img_label not in label_ids:\n",
    "                label_ids[img_label] = current_id\n",
    "                current_id += 1\n",
    "            id_ = label_ids[img_label]\n",
    "\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img_cv = np.array(img)\n",
    "\n",
    "            dets = detector(img_cv, 1)\n",
    "            \n",
    "            for k, d in enumerate(dets):\n",
    "                shape = sp(img_cv, d)\n",
    "                \n",
    "                embedding = facerec.compute_face_descriptor(img_cv, shape)\n",
    "                embedding = np.array(embedding)\n",
    "\n",
    "                embeddings_list.append(embedding)\n",
    "                labels.append(id_)\n",
    "\n",
    "X = np.array(embeddings_list)\n",
    "y = np.array(labels)\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X, y)\n",
    "\n",
    "with open(\"face_recognition_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "print(\"Model trained and saved as face_recognition_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
