{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontal_face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml')\n",
    "profile_face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_profileface.xml')\n",
    "\n",
    "def detect_and_draw_faces_combined(img):\n",
    "    print(\"Image shape:\", img.shape)\n",
    "    \n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        print(\"Image is converted into grayscale\")\n",
    "    else:\n",
    "        gray = img\n",
    "        print(\"Is the image already grayscale? It should have only 1 channel:\")\n",
    "\n",
    "    frontal_faces = frontal_face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    profile_faces = profile_face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    flipped_gray = cv2.flip(gray, 1)\n",
    "    flipped_profile_faces = profile_face_cascade.detectMultiScale(flipped_gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in flipped_profile_faces:\n",
    "        profile_faces = list(profile_faces)\n",
    "        profile_faces.append((gray.shape[1] - x - w, y, w, h))\n",
    "        profile_faces = tuple(profile_faces)\n",
    "\n",
    "    all_faces = list(frontal_faces) + list(profile_faces)\n",
    "\n",
    "    unique_faces = []\n",
    "    for face in all_faces:\n",
    "        face_tuple = tuple(face)\n",
    "        if face_tuple not in unique_faces:\n",
    "            unique_faces.append(face_tuple)\n",
    "\n",
    "    print(f\"Number of faces detected: {len(unique_faces)}\")\n",
    "\n",
    "    if len(unique_faces) > 0:\n",
    "        for (x, y, w, h) in unique_faces:\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "    else:\n",
    "        print(\"No faces detected.\")\n",
    "\n",
    "    if len(img.shape) == 3:\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "detect_and_draw_faces_combined(img_cv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device = dlib.cuda.get_num_devices()\n",
    "if cuda_device > 0:\n",
    "    print(\"CUDA is available. Using GPU for face detection.\")\n",
    "    detector = dlib.cnn_face_detection_model_v1('Models/mmod_human_face_detector.dat')\n",
    "else:\n",
    "    print(\"CUDA is not available. Falling back to CPU.\")\n",
    "    detector = dlib.cnn_face_detection_model_v1('Models/mmod_human_face_detector.dat')\n",
    "\n",
    "def detect_faces_Dlib(img):\n",
    "    img_resized = cv2.resize(img, (640, 480))\n",
    "    gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        x1, y1, x2, y2 = (face.rect.left(), face.rect.top(), face.rect.right(), face.rect.bottom())\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "    print(f\"Number of faces detected: {len(faces)}\")\n",
    "\n",
    "    if len(img.shape) == 3:\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    return len(faces)\n",
    "\n",
    "\n",
    "#detect_faces_Dlib(img_cv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_mtcnn(img, img_index, cropped_faces, default):\n",
    "    try:\n",
    "        correct_rotation = 0\n",
    "        highest_prob = 0.0\n",
    "        confidence_threshold = 0.80\n",
    "        length = 4\n",
    "        horizontal_preferred_dimensions = (1008, 756)\n",
    "        vertical_preferred_dimensions = (756, 1008)\n",
    "        valid_boxes = []\n",
    "        best_probs = []\n",
    "        found_landmarks = []\n",
    "\n",
    "        names = [name.strip() for name in df[\"label_name\"][img_index].split(';')]\n",
    "\n",
    "        for i in range(length):\n",
    "            empty_box = False\n",
    "            degrees = 90 * i\n",
    "            rotated_img = img\n",
    "\n",
    "            if degrees == 90:\n",
    "                rotated_img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "            elif degrees == 180:\n",
    "                rotated_img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "            elif degrees == 270:\n",
    "                rotated_img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "            height, width, _ = rotated_img.shape\n",
    "\n",
    "            if width > height:\n",
    "                scale = min(horizontal_preferred_dimensions[0] / width, horizontal_preferred_dimensions[1] / height)\n",
    "            else:\n",
    "                scale = min(vertical_preferred_dimensions[0] / width, vertical_preferred_dimensions[1] / height)\n",
    "\n",
    "            new_width = int(width * scale)\n",
    "            new_height = int(height * scale)\n",
    "            resized_img = cv2.resize(rotated_img, (new_width, new_height))\n",
    "\n",
    "            boxes, probs, landmarks = mtcnn.detect(resized_img, landmarks=True)\n",
    "\n",
    "            if boxes is None or probs is None or landmarks is None:\n",
    "                empty_box = True\n",
    "                boxes, landmarks = [], []\n",
    "\n",
    "            if not empty_box:\n",
    "                filtered = [\n",
    "                    (box, prob, landmark)\n",
    "                    for box, prob, landmark in zip(boxes, probs, landmarks)\n",
    "                    if prob >= confidence_threshold\n",
    "                ]\n",
    "                boxes, probs, landmarks = zip(*filtered) if filtered else ([], [], [])\n",
    "                boxes = sorted(boxes, key=lambda box: box[0])\n",
    "\n",
    "                for prob in probs:\n",
    "                    if prob > highest_prob:\n",
    "                        highest_prob = prob\n",
    "                        best_probs = probs\n",
    "                        valid_boxes = boxes\n",
    "                        found_landmarks = landmarks\n",
    "                        correct_rotation = degrees\n",
    "\n",
    "        if correct_rotation == 90:\n",
    "            img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "        elif correct_rotation == 180:\n",
    "            img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "        elif correct_rotation == 270:\n",
    "            img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        for box, landmark, prob in zip(valid_boxes, found_landmarks, best_probs):\n",
    "            height, width, _ = img.shape\n",
    "            x1, y1, x2, y2 = [int(coord) for coord in box]\n",
    "\n",
    "            x1 = int(x1 / scale)\n",
    "            y1 = int(y1 / scale)\n",
    "            x2 = int(x2 / scale)\n",
    "            y2 = int(y2 / scale)\n",
    "\n",
    "            x1 = max(0, min(x1, width - 1))\n",
    "            y1 = max(0, min(y1, height - 1))\n",
    "            x2 = max(0, min(x2, width - 1))\n",
    "            y2 = max(0, min(y2, height - 1))\n",
    "\n",
    "            cropped_face = img[y1:y2, x1:x2]\n",
    "\n",
    "            print(cropped_face.shape)\n",
    "\n",
    "            face_height, face_width, _ = cropped_face.shape\n",
    "            scale = min(160 / face_width, 160 / face_height)\n",
    "            resized_width = int(face_width * scale)\n",
    "            resized_height = int(face_height * scale)\n",
    "            resized_face = cv2.resize(cropped_face, (resized_width, resized_height))\n",
    "\n",
    "            padded_face = np.zeros((160, 160, 3), dtype=np.uint8)\n",
    "            y_offset = (160 - resized_height) // 2\n",
    "            x_offset = (160 - resized_width) // 2\n",
    "            padded_face[y_offset:y_offset + resized_height, x_offset:x_offset + resized_width] = resized_face\n",
    "\n",
    "            cropped_faces.append(padded_face)\n",
    "\n",
    "            if default:\n",
    "                default_folder = \"Cropped/default\"\n",
    "                os.makedirs(default_folder, exist_ok=True)\n",
    "            else:\n",
    "                person_folder = os.path.join(\"Cropped\", names[0])\n",
    "                os.makedirs(person_folder, exist_ok=True)\n",
    "\n",
    "            plt.imshow(padded_face)\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "        return len(valid_boxes)\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting faces in image index {img_index}: {e}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_mtcnn(img, img_index, cropped_faces, default):\n",
    "    try:\n",
    "        correct_rotation = 0\n",
    "        highest_prob = 0.0\n",
    "        confidence_threshold = 0.80\n",
    "        length = 4\n",
    "        horizontal_preferred_dimensions = (1008, 756)\n",
    "        vertical_preferred_dimensions = (756, 1008)\n",
    "        valid_boxes = []\n",
    "        best_probs = []\n",
    "        found_landmarks = []\n",
    "\n",
    "        names = [name.strip() for name in df[\"label_name\"][img_index].split(';')]\n",
    "\n",
    "        for i in range(length):\n",
    "            empty_box = False\n",
    "            degrees = 90 * i\n",
    "            rotated_img = img\n",
    "\n",
    "            # Rotate the image\n",
    "            if degrees == 90:\n",
    "                rotated_img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "            elif degrees == 180:\n",
    "                rotated_img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "            elif degrees == 270:\n",
    "                rotated_img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "            height, width, _ = rotated_img.shape\n",
    "\n",
    "            if width > height:\n",
    "                scale = min(horizontal_preferred_dimensions[0] / width, horizontal_preferred_dimensions[1] / height)\n",
    "            else:\n",
    "                scale = min(vertical_preferred_dimensions[0] / width, vertical_preferred_dimensions[1] / height)\n",
    "\n",
    "            new_width = int(width * scale)\n",
    "            new_height = int(height * scale)\n",
    "            resized_img = cv2.resize(rotated_img, (new_width, new_height))\n",
    "\n",
    "            boxes, probs, landmarks = mtcnn.detect(resized_img, landmarks=True)\n",
    "\n",
    "            if boxes is None or probs is None or landmarks is None:\n",
    "                empty_box = True\n",
    "                boxes, landmarks = [], []\n",
    "\n",
    "            if not empty_box:\n",
    "                filtered = [\n",
    "                    (box, prob, landmark)\n",
    "                    for box, prob, landmark in zip(boxes, probs, landmarks)\n",
    "                    if prob >= confidence_threshold\n",
    "                ]\n",
    "                boxes, probs, landmarks = zip(*filtered) if filtered else ([], [], [])\n",
    "                boxes = sorted(boxes, key=lambda box: box[0])\n",
    "\n",
    "                for prob in probs:\n",
    "                    if prob > highest_prob:\n",
    "                        highest_prob = prob\n",
    "                        best_probs = probs\n",
    "                        valid_boxes = boxes\n",
    "                        found_landmarks = landmarks\n",
    "                        correct_rotation = degrees\n",
    "\n",
    "        if correct_rotation == 90:\n",
    "            img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "        elif correct_rotation == 180:\n",
    "            img = cv2.rotate(img, cv2.ROTATE_180)\n",
    "        elif correct_rotation == 270:\n",
    "            img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        for box, landmark, prob in zip(valid_boxes, found_landmarks, best_probs):\n",
    "            height, width, _ = img.shape\n",
    "            x1, y1, x2, y2 = [int(coord) for coord in box]\n",
    "\n",
    "            x1 = int(x1 / scale)\n",
    "            y1 = int(y1 / scale)\n",
    "            x2 = int(x2 / scale)\n",
    "            y2 = int(y2 / scale)\n",
    "\n",
    "            x1 = max(0, min(x1, width - 1))\n",
    "            y1 = max(0, min(y1, height - 1))\n",
    "            x2 = max(0, min(x2, width - 1))\n",
    "            y2 = max(0, min(y2, height - 1))\n",
    "\n",
    "            cropped_face = img[y1:y2, x1:x2]\n",
    "            cropped_faces.append(cropped_face)\n",
    "\n",
    "            if default:\n",
    "                default_folder = \"Cropped/default\"\n",
    "                os.makedirs(default_folder, exist_ok=True)\n",
    "            else:\n",
    "                person_folder = os.path.join(\"Cropped\", names[0])\n",
    "                os.makedirs(person_folder, exist_ok=True)\n",
    "\n",
    "            #plt.imshow(cropped_face)\n",
    "            #plt.axis(\"off\")\n",
    "            #plt.show()\n",
    "\n",
    "        #plt.imshow(img)\n",
    "        #plt.axis(\"off\")\n",
    "        #plt.show()\n",
    "\n",
    "        return len(valid_boxes)\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting faces in image index {img_index}: {e}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redetect(img):\n",
    "    try:\n",
    "        boxes, _ = mtcnn.detect(img)\n",
    "\n",
    "        if boxes is None:\n",
    "            return False\n",
    "\n",
    "        for box in boxes:\n",
    "            x1, y1, x2, y2 = [int(coord) for coord in box]\n",
    "            #cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        #print(f\"Error detecting faces in image: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 435\n",
    "length = 1\n",
    "\n",
    "for i in range(length):\n",
    "    cropped_faces = []\n",
    "    position = i + start\n",
    "    img = cv2.imread(train_data[position])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "length = len(train_data)\n",
    "correct_detection = 0\n",
    "Bad_detection = 0\n",
    "default = False\n",
    "df_cd = []\n",
    "df_bd = []\n",
    "\n",
    "validation = pd.DataFrame(columns=['img', 'person'])\n",
    "\n",
    "folder_Path = \"FaceNet_A\"\n",
    "Check_FilePath = \"check\"\n",
    "\n",
    "shape_predictor_path = \"shape_predictor_68_face_landmarks.dat\"\n",
    "sp = dlib.shape_predictor(shape_predictor_path)\n",
    "\n",
    "for i in range(length):\n",
    "    cropped_faces = []\n",
    "    position = i + start\n",
    "    img = cv2.imread(train_data[position])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    detected = detect_faces_mtcnn(img, position, cropped_faces, default)\n",
    "\n",
    "    img_name = os.path.basename(train_data[position])\n",
    "    img_name = os.path.splitext(img_name)[0]\n",
    "    Label_names = [name.strip() for name in df[\"label_name\"][position].split(';')]\n",
    "    people = len(df[\"label_name\"][position].split(';'))\n",
    "\n",
    "    if detected == people:\n",
    "        correct_detection += 1\n",
    "        df_cd.append(train_data[position])\n",
    "\n",
    "        for d in range(people):\n",
    "            try:\n",
    "                face_img = cropped_faces[d]\n",
    "                face_img_rgb = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                face_rect = dlib.rectangle(0, 0, face_img.shape[1], face_img.shape[0])\n",
    "                shape = sp(face_img_rgb, face_rect)\n",
    "\n",
    "                aligned_face = dlib.get_face_chip(face_img_rgb, shape, size=150)\n",
    "\n",
    "                if default:\n",
    "                    Img_FilePath = os.path.join(folder_Path, \"default\", f\"{img_name}_{d}.jpg\")\n",
    "                else:\n",
    "                    Img_FilePath = os.path.join(folder_Path, Label_names[d], f\"{img_name}_{d}.jpg\")\n",
    "\n",
    "                \n",
    "                if not os.path.exists(Img_FilePath):\n",
    "                    os.makedirs(os.path.dirname(Img_FilePath), exist_ok=True)\n",
    "\n",
    "                cv2.imwrite(Img_FilePath, cv2.cvtColor(aligned_face, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "                new_row = pd.DataFrame({'img': [Img_FilePath], 'person': [Label_names[d]]})\n",
    "                validation = pd.concat([validation, new_row], ignore_index=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error aligning face {d} in {img_name}: {e}\")\n",
    "    else:\n",
    "        Bad_detection += 1\n",
    "        df_bd.append(train_data[position])\n",
    "\n",
    "    print(f\"Processed {i+1}/{length} images\")\n",
    "\n",
    "print(f\"{correct_detection}/{len(train_data)} were correctly detected (All faces were detected)\")\n",
    "print(f\"{Bad_detection}/{len(train_data)} were incorrectly detected (Not all faces were detected)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
